<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Zee Tsui</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Zee Tsui</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MRO、装饰器的调用顺序——Python 中需要注意的细节</title>
      <link>/posts/2021/20211227-mro%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E8%B0%83%E7%94%A8%E9%A1%BA%E5%BA%8Fpython-%E4%B8%AD%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%BB%86%E8%8A%82/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/posts/2021/20211227-mro%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E8%B0%83%E7%94%A8%E9%A1%BA%E5%BA%8Fpython-%E4%B8%AD%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%BB%86%E8%8A%82/</guid>
      <description>1. 重载运算符的调用顺序 class Foo: def __init__(self, name): self._name = name def __str__(self): return self._name def __eq__(self, other): return other is self class Bar(Foo): def __eq__(self, other): return str(self) == str(other) class Foo1: def __init__(self, name): self._name = name def __str__(self): return self._name def __eq__(self, other): return str(self) == str(other) foo = Foo(&amp;#34;Hello&amp;#34;) bar = Bar(&amp;#34;Hello&amp;#34;) foo1 = Foo1(&amp;#34;Hello&amp;#34;) print(foo == bar) # True, 调用了 bar 的 __eq__ print(bar == foo) # True, 调用了 bar 的 __eq__ print(foo == foo1) # False, 调用了 foo 的 __eq__ print(foo1 == foo) # True, 调用了 foo1 的 __eq__ Python 中，如果 == 符号两端变量属于具有继承关系的类，则会优先调用子类的重载方法；如果 == 符号两端变量分别属于两个完全不同的类，则会调用左端类的重载进行判断（见代码中print部分的后两个）</description>
    </item>
    
    <item>
      <title>用 Python 实现一个可自动识别的文件夹单向同步功能</title>
      <link>/posts/2021/20210327-%E7%94%A8-python-%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%8F%AF%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8D%95%E5%90%91%E5%90%8C%E6%AD%A5%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/posts/2021/20210327-%E7%94%A8-python-%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%8F%AF%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8D%95%E5%90%91%E5%90%8C%E6%AD%A5%E5%8A%9F%E8%83%BD/</guid>
      <description>写在前面：这是我对类 unison 这样猝发式同步工具的一种复现尝试；因为我平时主要就是在一个文件夹内进行操作，所以算法更为简单，并没有实现针对单个文件进行处理的双向同步。 我如今已经使用了更为高效易用的 FreeFileSync 去进行文件同步和备份操作，该程序已经归档。
为什么我想写这个算法 在日常生活以及学习中，文件夹同步这一操作自然是必不可少的，一个方便使用的文件同步软件可以很好的对这种进行操作。通过我以前的文章可以了解到，我之前一直都在使用 Unison 来进行本地以及 WSL 不同的文件夹间的同步。而后来由于自己的问题，更换电脑后，由于 Unison 麻烦的配置以及自己对于文件夹同步的想法，我还是想尝试自己写一个文件夹同步的算法。
文件夹同步的方式有两种，一种是 rsync 那样的单向同步，一种是 Unison 一样的双向同步（Unison 也是基于 rsync 的）；当然我更需要的是双向的，所以这就不由得涉及到了很多的同步问题，最后我还是改成实现一个自动识别主文件夹的单向同步，这同样也可以达到双向同步的效果。
算法细节 算法很简单，总共分为两个层面。首先是同步的工具，我直接使用了 rsync 来进行传输的操作，然后同步两个或多个文件夹即可；第二个部分就是判断哪个文件夹为同步的主文件夹，这一部分使用了文件的时间戳作为指纹保存，在同步之后，如果有与保存的指纹不同，则可判定其做了修改，即新文件夹。
时间戳生成算法 def timeset(path, data: dict, prefix: str): source = os.getcwd() path_list = os.listdir(path) os.chdir(path) for n in path_list: if os.path.isfile(n): if n != &amp;#39;syncing.json&amp;#39;: data[os.path.join(prefix, n)] = int(os.path.getmtime(n)) else: timeset(n, data, os.path.join(prefix, n)) os.chdir(source) return data 而如果在数据中没有指纹，则两个文件夹为新文件夹，此时直接取时间戳最大的文件夹。在判断完哪一个文件夹为同步的主文件夹之后，直接进行 rsync 同步即可。
算法源码 当然，为了保证该脚本的可用性，文件地址判定以及信息确认之类的都采用了严谨的写法，从而保证不会出现错误。
def sync_folder_local(*args, main=None): # WARNING: This function only works correctly with single-folder editing # It would have a bug occured when multi folders were edited database = load_json(f&amp;#39;{ os.</description>
    </item>
    
    <item>
      <title>谈谈我所认为的主流编程语言</title>
      <link>/posts/2020/20200422-%E8%B0%88%E8%B0%88%E6%88%91%E6%89%80%E8%AE%A4%E4%B8%BA%E7%9A%84%E4%B8%BB%E6%B5%81%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200422-%E8%B0%88%E8%B0%88%E6%88%91%E6%89%80%E8%AE%A4%E4%B8%BA%E7%9A%84%E4%B8%BB%E6%B5%81%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid>
      <description>呆在家里的时间越来越长了，这也给了我很多时间去做一些以前没有想过的思考。
所以趁着目前的学习阶段，我想谈谈我所认为的三种主流编程语言——C++、Java、Python。这三种语言有着不同的运行方式、不同的运用场景和不同的使用目的，也是我目前主要使用的三个编程语言。
C++ C++ 是我最早接触的语言之一了，早期的 C++ 更多地是 C 的一个不严谨的“超集”，你甚至可以在 C++ 的语法环境下编写 C 程序，两者相互兼容。后来的 C++ 17 / 18 反而越来越像“Python”，这也足以显示目前语言的一个发展方向。
的确如今的 C++ 复杂度已经过分高了，从而让开发者把更多的时间花在了指针以及内存管理等本可以自动处理的部分。这对于如今互联网企业的“敏捷开发”潮流来说十分不友好，如果贯彻 C++ 就需要花费大量时间搭建脚手架。
优点 优点显而易见，程序运行效率极高，接近于机器语言，并且相比于 C 有 OOP 的能力。所以这能够让 C++ 开发者在硬件层次上考虑问题，从而最大化利用硬件的性能。
所以这就特别适用于对运行速度要求很高，与系统底层相关的程序。
缺点 那它还有什么缺点呢？首当其冲的就是在开发过程中，工程师需要花费远超算法实现的时间（至少对于我来说是这样）去解决硬件资源管理和内存管理的问题，而这些问题往往与目前解决的问题无关。
第二点便是代码量和复杂的设计。这大概是历史原因，因为 C++ 一直在鼓励复杂的、精致的设计，导致了庞大的代码体积。
Java Java 是我最近学习的一种语言。期初我学习 Java 的兴趣并不高，但是后来的作业中用了一下，便继续深入了一点，现在大概还是初学者阶段吧。（笑）
因为我的 Java 经验并不是特别足，所以就简单对比一下 Java 与其他语言的优劣。
优点 优点很直观，就是“Write once, run anywhere”，这也是当初 Java 被设计出来的原因。因为 Java 需要先将代码编译成可供 JVM 运行的字节码，所以这也意味着程序可以完全不依赖与运行的平台，只要有 runtime 的运行环境即可。
其次便是 Java 的编程过程相较于 C++ 就轻松了很多，不仅比 C++ 小巧简单，而且有 GC，OOP，强类型，与 C 结合比较好。</description>
    </item>
    
    <item>
      <title>将自己的轮子部署到 PyPI</title>
      <link>/posts/2020/20200405-%E5%B0%86%E8%87%AA%E5%B7%B1%E7%9A%84%E8%BD%AE%E5%AD%90%E9%83%A8%E7%BD%B2%E5%88%B0-pypi/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200405-%E5%B0%86%E8%87%AA%E5%B7%B1%E7%9A%84%E8%BD%AE%E5%AD%90%E9%83%A8%E7%BD%B2%E5%88%B0-pypi/</guid>
      <description>自己写了一个效率高，功能简单易用的轮子，如何把它分享给其他人呢？部署到 PyPI 是一个不错方法。
包结构 一个正常的包结构如下（以 oneline 为例）：
- Folder - oneline - __init__.py - README.md - LISENCE - setup.py oneline 文件夹就是自己写的库了，为必须项； README.md 是库的文档介绍； LISENCE 是这个包所使用的协议； setup.py 是这个包的配置脚本，为必须项。 虽然 README.md 和 LISENCE 不是必须的，但有这两个文件能方便使用者使用。
setup.py setup.py 类似于一个配置的脚本，在生成和配置轮子的时候都会使用到。结构如下：
import setuptools with open(&amp;#34;README.md&amp;#34;, &amp;#34;r&amp;#34;, encoding=&amp;#34;utf-8&amp;#34;) as fh: long_description = fh.read() setuptools.setup( name=&amp;#39;one-line&amp;#39;, version=&amp;#39;0.1.31&amp;#39;, description=&amp;#39;Make every step oneLine.&amp;#39;, long_description=long_description, # 没有 README 这一项可以不要 long_description_content_type=&amp;#34;text/markdown&amp;#34;, install_requires=[ # 该包的依赖包，安装时会检查是否满足依赖要求 &amp;#39;pandas&amp;#39;, &amp;#39;seaborn&amp;#39;, &amp;#39;scipy&amp;#39;, &amp;#39;scikit-learn&amp;#39; ], packages=setuptools.find_packages(), # 该库中含有的包，一般就自动搜索 author=&amp;#39;Zeesain Tsui&amp;#39;, author_email=&amp;#39;clarenceehsu@163.</description>
    </item>
    
    <item>
      <title>使用 pyinstaller 打包程序及路径问题</title>
      <link>/posts/2020/20200317-%E4%BD%BF%E7%94%A8-pyinstaller-%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F%E5%8F%8A%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200317-%E4%BD%BF%E7%94%A8-pyinstaller-%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F%E5%8F%8A%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/</guid>
      <description>最近有一门课的小组任务要求完成 AES 加密算法，语言不限，并且提交一个完整的工程和测试程序，还要附上 README。因为对我来说难度稍微低一些，我就直接把这个给做完了。（微笑）
为了锻炼一下我的 Java 水平和能力，所以我一开始打算全部用 Java 来写，但后来因为偷懒不想写为了展现我们灵活而全面的技术栈，所以我就用 Python 写了一个文件对比的脚本。
pyinstaller 的安装 考虑到 Windows 各种各样的使用环境，我们直接发一个 .py 的脚本是不一定能够在其他电脑上正常运行的。因此为了方便就必须要给程序做打包，把 Python 的环境全部打包到一个二进制文件里面，这样就能够做到独立运行了。
pyinstaller 是一个专门用来做 Python 脚本打包的库，如果没有可通过 pip install pyinstaller 进行安装。
这里建议使用虚拟环境去安装 pyinstaller，它会根据环境中的库情况进行打包，如果使用的库多了会导致打包出来的程序会特别地大。如果在虚拟环境中做库的删改都会更加方便。
开始打包！ 完成安装后就可以开始打包的操作了，首先需要 cd 到 .py 文件对应的目录文件夹，这样就可以保证生成出来的文件都在目录里面，整理比较方便。
pyinstaller 常用的命令有两个：
pyinstaller -D app.py pyinstaller -F app.py 其中的 app.py 为要打包文件的相对地址，-D 是默认命令，即生成一个目录文件，里面包含了一个启动程序和一系列的依赖文件；-F 是生成单个可执行文件的命令，它生成 build 和 dist 文件夹，其中 dist 文件夹里面的可执行文件是可以单独使用的，其余项可以删掉。
它的原理很简单粗暴，就是将 Python 复制出来，连着脚本一起打包进去，执行的时候再全部解压到缓存文件夹里执行脚本文件。
路径问题 打包完成之后就可以拿出来使用了，因为里面集成了 Python 的 runtime 环境，所以不管电脑里面有没有装 Python，各种姿势使用都不会影响。
正当我以为完成之时，打开程序直接闪退。从 CMD 打开才发现程序出现了错误，要访问的文件访问不到，这时我才发现程序执行的目录（一个在 Roaming 中的缓存目录）和这个程序放的目录不是一致的，所以直接用相对地址根本访问不到所需要的文件。</description>
    </item>
    
    <item>
      <title>ASC20 比赛记录 - 3</title>
      <link>/posts/2020/20200303-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95-3/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200303-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95-3/</guid>
      <description>ASC20 比赛因为疫情的原因，proposal 的提交延期了一个多月，所以中间我也休息了一段时间。最近随着诸多工作的完成，ASC 20 的比赛之旅也渐渐到了尾声。
题目 这一次的赛题是有关 NLP 方向的，要在只使用 Pytorch 框架的情况下完成 Cloze 下游任务的设计，并且以准确率作为最终的分数计算。
主办方并未提供 baseline，只提供了数据集，格式为 json，具体如下：
{ &amp;#39;article&amp;#39;: &amp;#39;...&amp;#39;, &amp;#39;options&amp;#39;: [[words * 4] * 20], &amp;#39;answers&amp;#39;: [&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;... * 20] } 目前的进展及思路 在之前的训练的过程中出现了一个比较恼人的问题，最早我采用的是 4 分类，但是网络会出现不收敛的问题，我尝试了许多的手段（正如之前所提到的那样）也是没有办法去解决。后来经过检查和与师兄的讨论才发现作 4 分类本身就比较难作拟合——可能根本就没有拟合，毕竟样本太少，每一部分的文字又太多，导致 embedding 出来的矩阵差距较小。
后来采用了 2 分类效果就好了很多，因此目前训练的成果已经成功追上了 1 队。而且由于 Transformers 在训练的时候能够自动判断 GPU 的环境使用分布式训练，所以还是很顺畅地做了分布式训练。</description>
    </item>
    
    <item>
      <title>ASC20 比赛记录 - 2</title>
      <link>/posts/2020/20200208-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95-2/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200208-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95-2/</guid>
      <description>ASC20 比赛已经到了中段，是时候给最近的工作做一下总结了。
题目 这一次的赛题是有关 NLP 方向的，要在只使用 Pytorch 框架的情况下完成 Cloze 下游任务的设计，并且以准确率作为最终的分数计算。
主办方并未提供 baseline，只提供了数据集，格式为 json，具体如下：
{ &amp;#39;article&amp;#39;: &amp;#39;...&amp;#39;, &amp;#39;options&amp;#39;: [[words * 4] * 20], &amp;#39;answers&amp;#39;: [&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;... * 20] } 目前的进展及思路 之前所尝试过的预先填词的方法可行性不高，所以只能够将所有的词填进去。我们的算法是以每个空的四个选项去生成四句话，如果出现了一句话多个空的情况，则留空不填，然后以此生成了总共空数 * [ 4, 预填空句子 ] 的矩阵。
然后就得提取特征了，用 BERT 的预训练模型 bert-base-uncased 生成向量矩阵，其中每一句话都会生成一个 [1, 768] 的向量，然后存入 .npy 文件中。把答案的 ABCD 转换为 [1, 4] 的 onehot 向量，也存入另一个 .npy 文件中，供后面训练使用。
训练我们使用的是 BiLSTM + Attention Net，通过注意力机制来提高准确率。
存在问题 目前训练了几波，存在这一些问题：
out of memory 这个是老生常谈的问题了，主要的原因是 batch_size 设置得过大，从而导致显存使用过高。第二个是未终止之前的训练过程，之前通过 nohup 等手段运行的训练不会自动退出，需要主动 kill 掉。</description>
    </item>
    
    <item>
      <title>如何利用 BERT 提取句向量</title>
      <link>/posts/2020/20200118-%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-bert-%E6%8F%90%E5%8F%96%E5%8F%A5%E5%90%91%E9%87%8F/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200118-%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-bert-%E6%8F%90%E5%8F%96%E5%8F%A5%E5%90%91%E9%87%8F/</guid>
      <description>BERT 在 NLP 方向中是一个十分具有里程碑的模型，那么如何通过 BERT 提取一个句子的句向量呢？
网络上的资料还是很多的，由于比赛要求只使用 Pytorch 框架，所以很多基于 TF 的教程和库就没办法用了。在查询了部分资料后，我终于总结出了一个提取的方法：
这一篇总结我会尽力写得通俗易懂，一读就明白。
算法解释 import torch from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM 导入 torch 和 pytorch_pretrained_bert 库，站在巨人的肩膀上，直接缩短大量的训练时间。
tokenizer = BertTokenizer.from_pretrained(&amp;#39;bert-base-uncased&amp;#39;) # 导入预训练模型 tokenized_text = tokenizer.tokenize(text) # tokenize 输入的文本 indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # 向量化 这一部分的代码主要是将输入的文本转化为 tokenized 的文本，然后再把该文本给向量化。
问题来了，什么是 tokenized 和向量化？ tokenized 即标记化，把输入的句子进行标记划的操作，举个小例子：
tokenized_text = tokenizer.tokenize(&amp;#39;Hello world !&amp;#39;) &amp;gt;&amp;gt;&amp;gt; [&amp;#39;hello&amp;#39;, &amp;#39;world&amp;#39;, &amp;#39;!&amp;#39;] 大家可能注意到了，为什么字母全部为小写了？这是因为我们使用的模型 bert_base_uncased 是不分大小写的，所以输出的 tokenized_text 会全由小写表示。
其实 BERT 还支持输入两个句子，但是需要放在同一个字符串中，并通过一个标记来表示一个句子的开始和结束，再举个小例子：
tokenized_text = tokenizer.tokenize(&amp;#39;[CLS] Hello world!</description>
    </item>
    
    <item>
      <title>ASC20 比赛记录</title>
      <link>/posts/2020/20200116-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020/20200116-asc20-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/</guid>
      <description>ASC20 比赛在 1 月 6 号正式开始了，我在 1 月 10 号也正是接题开始了比赛的相关工作。因为这是我第一次以学校的名义参加全球性的赛事，所以特地记录下这段时间内的学习历程和思路。
题目 这一次的赛题是有关 NLP 方向的，要在只使用 Pytorch 框架的情况下完成 Cloze 下游任务的设计，并且以准确率作为最终的分数计算。
主办方并未提供 baseline，只提供了数据集，格式为 json，具体如下：
{ &amp;#39;article&amp;#39;: &amp;#39;...&amp;#39;, &amp;#39;options&amp;#39;: [[words * 4] * 20], &amp;#39;answers&amp;#39;: [&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;... * 20] } 学习 这一次的路线就非常直观了，需要走 NLP 方向，而 NLP 目前最为热门的网络模型就是 BERT。类似 ResNet 之于图像识别的网络，这是一个 NLP 中炙手可热，同时也十分常用的模型，而我们可以通过这个模型达到 word2vec 的效果，提取出文字中的向量信息，并输送到下层网络以完成下游任务。
所以我就打算使用 BERT 作为网络中的 embedding 部分，然后下层在进行 Cloze 的填空操作。在网上简单查找并且学习了 NLP的一些实现细节，我发现了 transformer 这个网红模型，并且有了许多的预训练模型，所以我便选择了以 transformer 为基础去完成题目。
目前的进展及思路 目前我已经基本看完了 transformer 中的 example 代码文件，并且对其工作原理有了基础的了解，可以开始准备数据集进行训练了。
我此外则有着以下的一些不成熟的小想法：
以我在观摩别人打比赛和自己比赛的经验，我会偏向于直接使用 pretrained 模型或者以其为底作迁移学习； 通过 BERT 提取特征并且进行猜词，然后与选项进行比对，如果不存在于选项中则需要通过比对 similarity，然后比较取最为相似的单词作为选择。 把选项放入原句中，然后通过 MRPC 下游任务计算句子的连贯性，取连贯性最高者。 考虑到上下文（比如 He or She 性别判断之类的选择），可能还需要通过另一个网络提取关键信息。 我针对第 2 点完成了基本的代码工作，但是目前就成果和效率来看，还是存在一定的不足，后续会对其进行改进，同时也会往多个方向进行探索~~，毕竟现在时间还多~~。</description>
    </item>
    
    <item>
      <title>防止过拟合和提高泛化能力的技巧</title>
      <link>/posts/2019/20191124-%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%8F%90%E9%AB%98%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E7%9A%84%E6%8A%80%E5%B7%A7/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20191124-%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%8F%90%E9%AB%98%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E7%9A%84%E6%8A%80%E5%B7%A7/</guid>
      <description>深度学习是一个很奇怪的过程，有人说它是“深度炼丹”，有人说它是一个黑盒，超参调整就是玄学。
事实上，我们不可能在深度学习中寻找到所谓的“最优解”，我们只能够在自己的能力范围之内寻找到局部的最优解，而如何提高自己网络模型的分类或者生成能力也自然有着许多的技巧。
数据 深度学习最需要的，就是数据，一个好的数据集可以让神经网络的训练事半功倍。在我看来，数据在保证质量的前提下多多益善，样本数据越多，模型拟合的效果就会越好。因此首先，尽可能多地寻找优质数据集。
Data Augmentation 而如果在数据集不够时，对数据的预处理就显得十分重要，对原先数据的处理扩增被称作 data augmentation，方法主要是下面的几种：
对于语音或者图像，可以在原本的数据上加噪声，或者进行缩放，镜像等操作； 对于数值类向量，可以在原先的数据基础上进行随机； 文字类数据，我觉得并不会缺少数据集（笑）。 在数据中添加噪声，或者平移缩放等操作在很多比赛以及网络中已经证明了，可以很好地提高模型的泛化能力。
数据归一化 这是一个老生常谈的问题了，提前把数据进行归一化可以很好地防止梯度爆炸。在网络中，我们也可以设置激活函数（sigmoid、tanh等）对数据进行归一化。而激活函数也容易造成梯度消失的问题，我们可以更换激活函数，或者进行 normalize，这会在另一篇文章里面讨论。
数据本身 最后还有一个方法，就是从数据本身寻找问题。举个例子，老师职位和性别有关吗？车速和天气有关系吗？答案是否定的，所以要检查数据集中的某些特征是不是与我们要预测或分类的特征毫无关联，如果是的话就尽量抛弃。
另外，如果有其他的特征或者更加适合的方法，也需要对数据进行调整。
算法 其实在我的很多情况下，当无法采取某种特定的算法去进行数据处理的时候，便会采用深度学习其训练拟合（笑）。
选择算法 什么算法对于特定的问题效果最好，我们是没有办法也不可能知道的，只能取范围内最优，即当前使用的算法并不一定适合当前的问题。
如果没有头绪的话，可以从下面几点进行尝试：
线性算法，如逻辑回归和线性判断分析 树模型，如 CART、随机森林等 SVM 或 KNN 等算法 神经网络模型，如 CNN、RNN、LSTM 然后根据经验和结果综合判断，选择目标模型进行调参或者优化，从而进一步提升效果。
之前比赛的时候有一个大佬的解法是训练两个网络进行对抗，这个算法拿了准确率第一，当时印象挺深刻的。
算法调优 调参是一个算法调优的必经之路，主要分为以下几点：
模型可诊断性，模型总是处于两种状态，即欠拟合和过拟合之间，只是程度不同罢了。我们可以把 accuracy 和 loss 输出在图表中，从而作为一个有价值的诊断工具。 权重的初始化，用小的随机数初始化权重。 学习率，学习率决定了梯度下降时的范围，如果添加了更多的神经节点和网络层，就可加大学习率。这一点并不是独立的，与 batch size 等都有关系。 激活函数，激活函数其实有很多种，而且每一种激活函数都有一段流行的时间，如今一般都会使用 ReLU 函数，但 ReLU 本身存在着死神经元的问题，然后又诞生了 Leaky ReLU。尝试不同的激活函数可能会有不同的效果。 网络结构，网络的结构设计也会很大程度影响性能，在一般情况下，最好使用成熟的网络，或者尝试发表论文中的网络。 batch size 和 epoch，batch size 决定了梯度值以及权重的更新频率，一般设置的越大计算的速度就越快，反之越慢；epoch 则是样本参与训练的循环次数。 正则项，这可以很好地解决过拟合，如 dropout。 优化方法和损失函数，现在在梯度下降的过程中有许多优化器。默认的梯度下降方法是得到一个结果，然后调整动量值、学习率进行优化，而复杂的优化器则会有更多的参数设置，这需要多尝试去积累经验。 提早结束训练，一旦效果变差了，可以及时停止优化训练。而这一部分可以直接通过 TensorFlow 或者 Pytorch 框架中的 checkpoint 功能，自动选择和保存相应的模型训练点。 宏观调整 最后边是调出神经网络这个视角，从宏观的角度出发，把神经网络作为一个个体去看待问题。</description>
    </item>
    
    <item>
      <title>让代码 Pythonic</title>
      <link>/posts/2019/20190828-%E8%AE%A9%E4%BB%A3%E7%A0%81-pythonic/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190828-%E8%AE%A9%E4%BB%A3%E7%A0%81-pythonic/</guid>
      <description>在 Python 中打上 import this，就会出现熟悉的 The Zen of Python。
&amp;gt;&amp;gt;&amp;gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&amp;#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced.</description>
    </item>
    
    <item>
      <title>车辆驾驶行为分析——比赛复盘（二）</title>
      <link>/posts/2019/20190822-%E8%BD%A6%E8%BE%86%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98%E4%BA%8C/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190822-%E8%BD%A6%E8%BE%86%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98%E4%BA%8C/</guid>
      <description>这一部分是比赛的思路复盘，由于时隔两个多月，只能够写个大概。
数据预处理 在前面简单地抽出了一些文件进行了人工分析，我们发现数据出现了不同程度的遗漏，并且经纬度的值也会有着很大的偏差。于是乎现在就需要将所有的数据进行预处理，从而方便后面的分析。
缺失值。缺失值我们采用常规的处理手段，即缺失值中的速度值和角度值等全部继承上一个点的数据；经纬度用上一个点的经纬度、速度和角度进行计算。 经纬度漂移。这个地方其实比较玄学，因为经纬度可以通过算法结合速度、角度进行计算，然而这两个参数所给的数据也存在误差。所以导致一段路上的经纬度利用算法修正也会存在一定量的漂移；后来我们尝试使用高德地图的绑路 API ，但是由于数据的限制以及调用次数的限制也存在瓶颈；再后来我们尝试动态修复，即经纬度出错的地方用速度和角度修正，速度角度出错的地方我们用经纬度修正（在第一步实现的情况下），但判断阈值很难敲定。于是最后我们选择相信速度角度数据的准确性，然后找出漂移的区块进行修正。 预处理后，丢弃一部分无用数据，然后送入分析算法之中分析。
分析维度 一级指标 阈值界定 疲劳驾驶 采用驾驶人连续驾驶时间不得超过 4 小时，每次停车休息时间不少于 20 分钟的标准界定疲劳驾驶 急加速 设定急加速行为的加速度阈值为 3m/s² ，为避免误差，计算加速度时间间隔取为 3s 急减速 设定急加速行为的加速度阈值为 -3m/s² ，为避免误差，计算加速度时间间隔取为 3s 怠速预热 怠速预热的条件：行驶速度 v = 0；ACC 状态为 on； 超长怠速 超长怠速的条件：行驶速度 v = 0；ACC 状态为 on；怠速预热时间 t ≥ 60s 熄火滑行 熄火滑行的条件：ACC 状态为 off；速度 0 &amp;lt; V &amp;lt; 5km/h；持续时间 t ≥ 3s 超速 条件：速度 ≥ 60km/h；持续 3s 或以上 急变道 短时间内的角度变化范围在 (20°, 70°) 之间；持续时间 3-5s 上文中所有的阈值以及判断标准均是采用了国家标准或者行业规定及习惯，从而确保准确性。超速那一部分需要读取到每一个经纬度所对应的地理位置，由于调用 API 的次数有限，加之大部分的行驶路段为城市公路，所以定位了 60km/h。</description>
    </item>
    
    <item>
      <title>如何解决 selenium 的退出问题？ - 关于 Python 函数的运行机制</title>
      <link>/posts/2019/20190806-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-selenium-%E7%9A%84%E9%80%80%E5%87%BA%E9%97%AE%E9%A2%98-%E5%85%B3%E4%BA%8E-python-%E5%87%BD%E6%95%B0%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190806-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3-selenium-%E7%9A%84%E9%80%80%E5%87%BA%E9%97%AE%E9%A2%98-%E5%85%B3%E4%BA%8E-python-%E5%87%BD%E6%95%B0%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</guid>
      <description>最近在搞爬虫，然后顺便写了写基于 selenium 框架的模拟登陆脚本供以后需要时用，然而在这时我发现了一个问题：
代码一开始是这样的：
from selenium import webdriver driver = webdriver.Chrome() driver.maximize_window() driver.get(&amp;#39;http://mail.163.com&amp;#39;) driver.find_element_by_id(&amp;#39;switchAccountLogin&amp;#39;).click() iframe = driver.find_element_by_xpath(&amp;#39;//*[@id=&amp;#34;loginDiv&amp;#34;]/iframe&amp;#39;) # 使用Xpath选定位到iframe driver.switch_to.frame(iframe)　# 切换iframe # iframe = driver.find_element_by_xpath(&amp;#34;//iframe[contains(@id, &amp;#39;x-URS-iframe&amp;#39;)]&amp;#34;) # 使用Xpath提供的contains定位 # driver.switch_to.frame(iframe) driver.find_element_by_name(&amp;#39;email&amp;#39;).send_keys(&amp;#39;name&amp;#39;) driver.find_element_by_name(&amp;#39;password&amp;#39;).send_keys(&amp;#39;password&amp;#39;) driver.find_element_by_id(&amp;#39;dologin&amp;#39;).click() 然后进行了简单的改造：
from selenium import webdriver class Mail163: def __init__(self, name, password): self.name = name self.password = password self.driver = webdriver.Chrome() def run(self): # driver.maximize_window() self.driver.get(&amp;#39;http://mail.163.com&amp;#39;) self.driver.find_element_by_id(&amp;#39;switchAccountLogin&amp;#39;).click() iframe = self.driver.find_element_by_xpath(&amp;#39;//*[@id=&amp;#34;loginDiv&amp;#34;]/iframe&amp;#39;) # 使用Xpath选定位到iframe self.driver.switch_to.frame(iframe) # 切换iframe # iframe = driver.</description>
    </item>
    
    <item>
      <title>Django 所踩过的坑</title>
      <link>/posts/2019/20190722-django-%E6%89%80%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190722-django-%E6%89%80%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</guid>
      <description>目前市面上流行着两个基于 Python 的 Web 框架，一个是 Django，一个是 Flask。（当然还有其他的如 Pylon 等，只是我没有接触过所以不做讨论）
由于 Hexo 博客系统的机制以及诸多的限制，我计划将我的博客从原本的基于 Hexo 静态框架转为基于 Django 框架的博客系统。
总所周知， Django 的架构比较适合于大型项目的开发，Flask 则是轻量级的 Web 框架，适合于小型项目开发。处于学习目的，我这次的框架选择十分的干脆——直接上 Django，所以我就直接开始了 Django 的学习。
当然，在建立这个博客系统的时候，作为一个接触 Web 较少的菜鸟，我也是踩了非常多的坑的。
端口开放 这个错误就非常初级了，当时我一直以为阿里云的服务器和腾讯云的服务器一样是端口全开的，所以我就直接把开发服务器放到了 8000 端口，结果什么都没有。所以后来在阿里云控制台打开了 8000 端口的监听才成功看到 Hello World 页面。
Django 不同版本之间的区别 由于 Django 迭代了很多次，它也像 Python 一样存在着版本之间的兼容性问题。Django 1 与 Django 2 之间就存在着非常多的语法以及参数上的区别，下面这个问题就困扰了我很久。
在 Django 2.0 之后，定义外键和一对一关系的时候需要加 on_delete 选项，此参数为了避免两个表里的数据不一致问题，否则就会报错： TypeError: __init__() missing 1 required positional argument: &#39;on_delete&#39; 所以要将 category = models.ForeignKey(Category) 改为 category = models.</description>
    </item>
    
    <item>
      <title>车辆驾驶行为分析——比赛复盘（一）地图生成</title>
      <link>/posts/2019/20190607-%E8%BD%A6%E8%BE%86%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98%E4%B8%80%E5%9C%B0%E5%9B%BE%E7%94%9F%E6%88%90/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190607-%E8%BD%A6%E8%BE%86%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98%E4%B8%80%E5%9C%B0%E5%9B%BE%E7%94%9F%E6%88%90/</guid>
      <description>最近比赛结果出来了，所以我打算对比赛做一个复盘，作日后参考之用。
我们的队伍有幸拿了全国二等奖，我在其中负责的是算法以及编程实现。
因为整个比赛时长只有七天，算法没有时间做特别多的优化，所以代码的质量可能不是特别高。
本人水平有限，若有缺漏之处欢迎指正。
研究问题 利用附件 1 所给数据，提取并分析车辆的运输路线以及其在运输过程中的速度、加速度等行车状态。提交附表中 10 辆车每辆车每条线路在经纬度坐标系下的运输线路图及对应的行车里程、平均行车速度、急加速急减速情况。
利用附件 1 所给数据，挖掘每辆运输车辆的不良驾驶行为，建立行车安全的评价模型，并给出评价结果。
综合考虑运输车辆的安全、效率和节能，并结合自然气象条件与道路状况等情况， 为运输车辆管理部门建立行车安全的综合评价指标体系与综合评价模型。
附表
序号 1 2 3 4 5 6 7 8 9 10 车牌号 AA00002 AB00006 AD00003 AD00013 AD00053 AD00083 AD00419 AF00098 AF00131 AF00373 数据说明 附件 1 给出 450 辆运输车辆的行车轨迹采集数据，由于采集设备精度，实际采集数据可能存在某些异常。 序号 指标名称 指标说明 说明 1 vehicleplatenumber 车牌号码 2 device_num 设备号 3 direction_angle 方向角 范围：0-359（方向角指从定位点的正北方向 起，以顺时针方向至行驶方向间的水平夹角） 4 lng 经度 东经 5 lat 纬度 北纬 6 acc_state ACC 状态 点火 1/熄火 0 7 right_turn_signals 右转向灯 灭 0/开 1 8 left_turn_signals 左转向灯 灭 0/开 1 9 hand_brake 手刹 灭 0/开 1 10 foot_brake 脚刹 无 0/有 1 11 location_time 采集时间 12 gps_speed GPS 速度 单位：km/h 13 mileage GPS 里程 单位：km 附件 2 给出 2018 年 7 月 30 日至 2018 年 10 月 10 日全国主要城市的自然气象数据。 序号 指标名称 指标说明 说明 1 province 省/自治区/直辖市 2 prefecture_city 地级市 3 county 县级市/县 4 wind_direction 风向 5 wind_power 风力 6 high_temp 最高温度 7 low_temp 最低温度 8 conditions 天气状况 如：多云、晴、雨、雪 9 relative_humidity 相对湿度 10 precipitation 降水量 单位：mm 11 record_date 采集日期 在车辆运输过程中，不良驾驶行为主要包括疲劳驾驶、急加速、急减速、怠速预热、超长怠速、熄火滑行、超速、急变道等。 数据类型样例 下面附上数据的样例截图：</description>
    </item>
    
    <item>
      <title>写了一个腾讯 AI 开放平台 SDK</title>
      <link>/posts/2019/20190528-%E5%86%99%E4%BA%86%E4%B8%80%E4%B8%AA%E8%85%BE%E8%AE%AF-ai-%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0-sdk/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190528-%E5%86%99%E4%BA%86%E4%B8%80%E4%B8%AA%E8%85%BE%E8%AE%AF-ai-%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0-sdk/</guid>
      <description>最近打算把 Jarvis 的部分外接功能从百度 AI 平台转到腾讯 AI 平台，但是腾讯 AI 并没有提供 SDK，所以自己写了一个分享出来。
这里面与百度 AI 平台之间主要的区别是腾讯的平台有一个鉴权机制，在调用 API 时除了一些基本参数之外，还需要提供一个根据 API 所需所有参数字典算出来的一个 MD5 码。格式以官方的 DEMO 作为参考并做了一定的改动，可读性相比 DEMO 有一定提高。
项目地址：Tencent_aiplat_SDK
源码如下：（与最终版本可能会有差别，以 GitHub 上的项目内代码为主）
# _*_ coding:utf-8 _*_ import hashlib import urllib.parse import urllib.request import urllib.error import json import time import base64 import os # 接口api url_prefix = &amp;#39;https://api.ai.qq.com/fcgi-bin/&amp;#39; class AiPlat(object): def __init__(self, app_id, app_key): self.app_id = app_id self.app_key = app_key self.data = {} def genSignString(self, parser): uri_str = &amp;#39;&amp;#39; for key in sorted(parser.</description>
    </item>
    
    <item>
      <title>从零开始做 Jarvis——基于 Python 的智能语音管家（二）语音识别</title>
      <link>/posts/2019/20190522-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A-jarvis%E5%9F%BA%E4%BA%8E-python-%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E7%AE%A1%E5%AE%B6%E4%BA%8C%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190522-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A-jarvis%E5%9F%BA%E4%BA%8E-python-%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E7%AE%A1%E5%AE%B6%E4%BA%8C%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/</guid>
      <description>让我们用Python去做一个Jarvis吧！
这一部分主要是语音识别部分的Python实现，而且由于这是我利用课余时间而作，所以相对于其他的项目而言进度可能并不会特别迅速，更新缓慢且随缘。
序 那我们就从前面的框架开始动手实现我们的 Jarvis，首先给大家看一下我的文件目录框架：
其中我把所有自己写的py模块统一归入_module文件夹，供main.py调取，_sounds文件夹存着因为语音识别以及TTS产生的音频文件。
因为目前的结构还不是特别庞大，可能后面会因为管理或者功能增加等等的原因进行修正。如果有改动我会在后面进行补充。
作为一个懒人程序员，并且本着不重复造轮子的原则，我决定先到网上搜一搜有没有现成的解决方案能够直接使用的。
Emmm&amp;hellip; 貌似没有，但这并不影响我们的功能实现。
我们把语音识别的问题拆分开来，便是：
麦克风录音 语音识别成文本 返回文本 然而幸运的是，百度在语音识别方面有着成熟的API以及SDK提供使用，所以在这个方面我们真正需要自己实现的部分只有录音方面了。
后期补充：目前我将这一方面的算法转用腾讯 AI 平台实现，并为此写了一套 SDK，如有需要的话可以参考我的项目。 这并不影响下面百度平台的实现。
语音录入生成.wav文件 我将语音录入的方法写在了recognition.py中，与语音识别等功能放在一起便于调用和管理，后续编辑也会方便一些。
在语音录入方面我们需要调用Pyaudio和wave模块，如果没有安装的话可以通过pip、conda或者Pycharm安装，方法这里就不赘述了。
然后首先我们需要导入这两个模块：
import pyaudio import wave 然后便是具体的方法实现，我写了一个def audio_record，这个部分的功能便完成了录音，并且会将录音保存为.wav格式。
def audio_record(out_file, rec_time): # out_file:输出音频文件名, rec_time:音频录制时间(秒) CHUNK = 1024 FORMAT = pyaudio.paInt16 # 16bit编码格式 CHANNELS = 1 # 单声道 RATE = 16000 # 16000采样频率 p = pyaudio.PyAudio() # 创建音频流 stream = p.open(format=FORMAT, # 音频流wav格式 channels=CHANNELS, # 单声道 rate=RATE, # 采样率16000 input=True, frames_per_buffer=CHUNK) print(&amp;#34;I&amp;#39;m listening.</description>
    </item>
    
    <item>
      <title>从零开始做 Jarvis——基于 Python 的智能语音管家（一）</title>
      <link>/posts/2019/20190521-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A-jarvis%E5%9F%BA%E4%BA%8E-python-%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E7%AE%A1%E5%AE%B6%E4%B8%80%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019/20190521-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A-jarvis%E5%9F%BA%E4%BA%8E-python-%E7%9A%84%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E7%AE%A1%E5%AE%B6%E4%B8%80%E7%AE%80%E4%BB%8B/</guid>
      <description>让我们用 Python 去做一个 Jarvis 吧！
这一部分主要是先前的大体介绍，而且由于这是我利用课余时间而作，所以相对于其他的项目而言进度可能并不会特别及时，更新缓慢且随缘。
序 先简单地做一下项目介绍。
在一次比赛现场与朋友攀谈，并由此激发了一个一直存于我内心的想法——做出像钢铁侠的 Jarvis 一般的智能助手。它能够在日常生活和工作学习中为我及时提供建议以及我所需要的信息，还能够帮我管理我的社交网络以及我的各种数码设备等等。
当时与朋友聊完这个宏大愿景后，我便留下了不学无术的泪水（毕竟能力有限 TAT）。所以结合目前的状况，我简单地对其可行性进行了进一步的思考和完善。
其实，从技术上实现一个在生活辅助方面的智能语音助手并不难。而现有的产品之所以功能并非如此强大，更多是公司的商业考量和对用户隐私的保护。
所以，怎么做？ 迫于技术上的压力，我目前的暂时性目标，是做出一个“简易版”的 Jarvis。它离真正的“人工智能”有着一定的距离，定位是一个在日常的工作和学习中能够帮得上忙的（至少比我手机上的小爱要来的有用的）“智能程序”。
所以围绕着这个，我产生了以下的想法：
首先要做到的是我们的 Jarvis 能够对我们说的话有基本的反应行为，比如查查天气、问些问题、聊聊天，诸如此类。其次便是一些高级的操作，比如随时检索我们彼时工作或者学习等方面所需要的任何信息；根据我们的情况作出合理的决策；跨设备交互和智能的设备控制和管理等等。 然后便是怎么做？截至我写作的时间，由于我的 Python 方面做过的项目比较多，所以选择了 Python 作为主要语言。
从结构上来看，我们如果要实现一个闭环，就需要做到语音识别，NLP，信息处理和分析，语音（或者画面）反馈。由于我有着 Jarvis 情怀，所以我会倾向于先完成语音部分的反馈环节。 至此，我们完成了整个项目的大致框架，显然，我们后续的程序框架以及整体思路也会依照这个来展开。
下一个部分，我会介绍语音识别部分实现。
Peace.</description>
    </item>
    
  </channel>
</rss>
